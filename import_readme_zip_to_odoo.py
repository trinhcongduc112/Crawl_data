# =============================================================
# File: import_readme_zip_to_odoo.py
# Import tr·ª±c ti·∫øp t·ª´ ReadMe ZIP export v√†o Odoo
# =============================================================

import os
import re
import yaml
import json
import base64
import markdown
import sys
import xmlrpc.client
from pathlib import Path
from typing import Dict, List, Tuple, Any, Optional

# Fix encoding for Windows console
if sys.platform == 'win32':
    sys.stdout.reconfigure(encoding='utf-8')

# ===================== C·∫§U H√åNH =====================
README_EXPORT_DIR = r"C:\Abivin\data_docs03\abivin-v4.0-2025-11-03T16-58-05_8cddcbc"
ODOO_BASE_URL = "https://test018.odoo.com"
ODOO_DB_NAME = "test018"
ODOO_USER = "trinhcongduc0112@gmail.com"
ODOO_API_KEY = "3f623d85508792f81af911610db742d67a5d1845"
SPACE_NAME = "T√†i li·ªáu Abivin 03"
MODEL_ARTICLE = "knowledge.article"
MODEL_ATTACHMENT = "ir.attachment"
# ====================================================

# Section priority mapping
SECTION_PRIORITY = {
    "Getting Started": 0,
    "Data Dictionary": 1,
    "Web App Tutorials": 2,
    "HDSD ·ª®ng D·ª•ng Web": 3,
    "Mobile App Tutorials": 4,
    "WMS and TMS Processes": 5,
    "Processes & Policies": 6,
    "Miscellaneous Support": 7,
    "FAQs": 8,
    "reference": 9,  # Developer Guide / API Reference
    "recipes": 10,  # Recipes
}

# Cache upload ·∫£nh ƒë·ªÉ tr√°nh upload tr√πng
IMAGE_UPLOAD_CACHE: Dict[str, str] = {}

# ---------------- ATTACHMENT UTILS -------------------
def guess_mimetype(name: str) -> str:
    ext = os.path.splitext(name.lower())[1]
    return {
        ".png": "image/png",
        ".jpg": "image/jpeg",
        ".jpeg": "image/jpeg",
        ".gif": "image/gif",
        ".svg": "image/svg+xml",
        ".webp": "image/webp"
    }.get(ext, "application/octet-stream")


def upload_attachment(models, uid, path: str, public=True) -> Tuple[Optional[int], Optional[str]]:
    try:
        with open(path, "rb") as f:
            datas_b64 = base64.b64encode(f.read()).decode()
        att_id = odoo_create(models, uid, MODEL_ATTACHMENT, {
            "name": os.path.basename(path),
            "datas": datas_b64,
            "mimetype": guess_mimetype(path),
            "public": public
        })
        url = f"/web/content/{att_id}"
        return att_id, url
    except Exception as e:
        print(f"  ‚úó L·ªói upload ·∫£nh '{path}': {e}")
        return None, None

# ---------------- XML-RPC CORE ----------------------
def odoo_login() -> Tuple[xmlrpc.client.ServerProxy, int]:
    print("\nüîê ƒêang k·∫øt n·ªëi v·ªõi Odoo...")
    common = xmlrpc.client.ServerProxy(f"{ODOO_BASE_URL}/xmlrpc/2/common")
    
    try:
        version_info = common.version()
        print(f"  ‚úì Server version: {version_info.get('server_version', 'Unknown')}")
    except Exception as e:
        print(f"  ‚úó L·ªói ki·ªÉm tra phi√™n b·∫£n: {e}")
    
    uid = common.authenticate(ODOO_DB_NAME, ODOO_USER, ODOO_API_KEY, {})
    if not uid:
        raise SystemExit("‚ùå X√°c th·ª±c Odoo th·∫•t b·∫°i. Ki·ªÉm tra l·∫°i API key ho·∫∑c quy·ªÅn truy c·∫≠p.")
    print(f"  ‚úì ƒê√£ ƒëƒÉng nh·∫≠p v√†o Odoo v·ªõi user ID: {uid}")
    return xmlrpc.client.ServerProxy(f"{ODOO_BASE_URL}/xmlrpc/2/object"), uid


def odoo_call(models, uid, model, method, *args, **kwargs):
    args = list(args) if args else []
    kwargs = kwargs or {}
    for attempt in range(3):
        try:
            return models.execute_kw(
                ODOO_DB_NAME, uid, ODOO_API_KEY,
                model, method, args, kwargs
            )
        except Exception as e:
            print(f"  [RPC ERROR] {model}.{method} attempt {attempt+1}/3: {e}")
            import time
            time.sleep(2)
    raise RuntimeError(f"‚ùå G·ªçi RPC {model}.{method} th·∫•t b·∫°i sau 3 l·∫ßn.")


def odoo_search(models, uid, model, domain, fields=None, limit=0):
    kwargs = {}
    if fields:
        kwargs["fields"] = fields
    if limit:
        kwargs["limit"] = limit
    return odoo_call(models, uid, model, "search_read", domain, **kwargs)


def odoo_create(models, uid, model, vals):
    if not isinstance(vals, dict):
        raise TypeError("Gi√° tr·ªã truy·ªÅn v√†o create() ph·∫£i l√† dict.")
    return odoo_call(models, uid, model, "create", vals)


def odoo_write(models, uid, model, ids, vals):
    if not isinstance(ids, list):
        ids = [ids]
    if not isinstance(vals, dict):
        raise TypeError("Gi√° tr·ªã truy·ªÅn v√†o write() ph·∫£i l√† dict.")
    return odoo_call(models, uid, model, "write", ids, vals)


# ---------------- HELPER FUNCTIONS -------------------
def ensure_space(models, uid, space_name: str) -> int:
    """T√¨m ho·∫∑c t·∫°o space trong Odoo"""
    print(f"\nüìÅ Ki·ªÉm tra kh√¥ng gian l√†m vi·ªác: '{space_name}'...")
    rec = odoo_search(models, uid, MODEL_ARTICLE, [("name", "=", space_name)], ["id"], limit=1)
    if rec:
        print(f"  ‚úì ƒê√£ t√¨m th·∫•y kh√¥ng gian l√†m vi·ªác: '{space_name}' (ID: {rec[0]['id']})")
        return rec[0]['id']
    print(f"  + T·∫°o m·ªõi kh√¥ng gian '{space_name}'...")
    space_id = odoo_create(models, uid, MODEL_ARTICLE, {
        "name": space_name,
        "body": "<p>Kh√¥ng gian ch·ª©a t√†i li·ªáu imported t·ª´ ReadMe ZIP export</p>"
    })
    print(f"  ‚úì ƒê√£ t·∫°o m·ªõi space (ID: {space_id})")
    return space_id


def read_order_yaml(order_path: Path) -> List[str]:
    """ƒê·ªçc _order.yaml v√† tr·∫£ v·ªÅ danh s√°ch slug/folder theo th·ª© t·ª±"""
    if not order_path.exists():
        return []
    try:
        with open(order_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()
        # Parse YAML list format: "- item1\n- item2\n"
        items = []
        for line in lines:
            line = line.strip()
            if line.startswith('- '):
                items.append(line[2:].strip())
        return items
    except Exception as e:
        print(f"  ‚ö†Ô∏è  L·ªói ƒë·ªçc {order_path}: {e}")
        return []


def operation_id_to_path_method(operation_id: str) -> Tuple[Optional[str], Optional[str]]:
    """Convert operationId nh∆∞ 'post_customers-create' th√†nh path v√† method"""
    if not operation_id:
        return None, None
    
    # Format: {method}_{path-with-dashes}
    # V√≠ d·ª•: post_customers-create -> method=post, path=/customers/create
    parts = operation_id.split('_', 1)
    if len(parts) != 2:
        return None, None
    
    method = parts[0].lower()
    path_part = parts[1].replace('-', '/')
    
    # T·∫°o path v·ªõi leading slash
    path = f"/{path_part}"
    
    return path, method


def parse_openapi_endpoint(openapi_spec: dict, operation_id: str, title: str = None) -> str:
    """Parse m·ªôt endpoint t·ª´ OpenAPI spec d·ª±a tr√™n operationId ho·∫∑c title"""
    html_parts = []
    found_endpoint = None
    found_path = None
    found_method = None
    
    # Th·ª≠ t√¨m b·∫±ng operationId tr∆∞·ªõc (n·∫øu c√≥)
    if operation_id:
        for path, methods in openapi_spec.get("paths", {}).items():
            for method, details in methods.items():
                if method.lower() in ["get", "post", "put", "patch", "delete", "head", "options"]:
                    if details.get("operationId") == operation_id:
                        found_endpoint = details
                        found_path = path
                        found_method = method
                        break
            if found_endpoint:
                break
    
    # N·∫øu kh√¥ng t√¨m th·∫•y b·∫±ng operationId, th·ª≠ convert operationId sang path+method
    if not found_endpoint and operation_id:
        path_pattern, method_pattern = operation_id_to_path_method(operation_id)
        if path_pattern and method_pattern:
            for path, methods in openapi_spec.get("paths", {}).items():
                # So kh·ªõp path (c√≥ th·ªÉ c√≥ params nh∆∞ {id})
                if path_pattern in path or path == path_pattern:
                    if method_pattern in methods:
                        found_endpoint = methods[method_pattern]
                        found_path = path
                        found_method = method_pattern
                        break
                if found_endpoint:
                    break
    
    # N·∫øu v·∫´n kh√¥ng t√¨m th·∫•y v√† c√≥ title, th·ª≠ t√¨m b·∫±ng title
    # Title th∆∞·ªùng c√≥ format: /customers/create
    if not found_endpoint and title:
        # Title c√≥ th·ªÉ l√† path lu√¥n
        title_path = title.strip()
        if title_path.startswith('/'):
            for path, methods in openapi_spec.get("paths", {}).items():
                if path == title_path or title_path in path:
                    # Th·ª≠ t√¨m method ph√π h·ª£p (∆∞u ti√™n post n·∫øu c√≥)
                    for method in ['post', 'get', 'put', 'patch', 'delete']:
                        if method in methods:
                            found_endpoint = methods[method]
                            found_path = path
                            found_method = method
                            break
                    if found_endpoint:
                        break
    
    if found_endpoint:
        summary = found_endpoint.get("summary", found_path or title or "API Endpoint")
        description = found_endpoint.get("description", "")
        
        html_parts.append(f"<h2>{summary}</h2>")
        if description:
            md = markdown.Markdown(extensions=['fenced_code', 'tables', 'nl2br'])
            html_parts.append(md.convert(description))
        
        if found_method:
            html_parts.append(f"<p><strong>Method:</strong> <code>{found_method.upper()}</code></p>")
        if found_path:
            html_parts.append(f"<p><strong>Path:</strong> <code>{found_path}</code></p>")
        
        # Parameters
        params = found_endpoint.get("parameters", [])
        if params:
            html_parts.append("<h3>Parameters</h3><ul>")
            for param in params:
                param_name = param.get("name", "")
                param_in = param.get("in", "")
                param_desc = param.get("description", "")
                param_req = param.get("required", False)
                html_parts.append(f"<li><code>{param_name}</code> ({param_in})")
                if param_req:
                    html_parts.append(" <strong>[Required]</strong>")
                if param_desc:
                    html_parts.append(f": {param_desc}")
                html_parts.append("</li>")
            html_parts.append("</ul>")
        
        # Request Body
        request_body = found_endpoint.get("requestBody", {})
        if request_body:
            html_parts.append("<h3>Request Body</h3>")
            req_desc = request_body.get("description", "")
            if req_desc:
                md = markdown.Markdown(extensions=['fenced_code', 'tables', 'nl2br'])
                html_parts.append(md.convert(req_desc))
        
        # Responses
        responses = found_endpoint.get("responses", {})
        if responses:
            html_parts.append("<h3>Responses</h3>")
            for status, resp in responses.items():
                html_parts.append(f"<h4>HTTP {status}</h4>")
                resp_desc = resp.get("description", "")
                if resp_desc:
                    md = markdown.Markdown(extensions=['fenced_code', 'tables', 'nl2br'])
                    html_parts.append(md.convert(resp_desc))
        
        return "".join(html_parts)
    
    return "<p>API endpoint documentation not found in OpenAPI spec.</p>"


def parse_markdown_file(md_path: Path, base_dir: Path = None) -> Dict[str, Any]:
    """Parse markdown file v√† tr·∫£ v·ªÅ dict v·ªõi title, content, metadata"""
    if not md_path.exists():
        return None
    
    try:
        with open(md_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # Parse front matter
        front_matter = {}
        body = content
        
        if content.startswith('---'):
            parts = content.split('---', 2)
            if len(parts) >= 3:
                try:
                    front_matter = yaml.safe_load(parts[1]) or {}
                    body = parts[2].strip()
                except:
                    body = content
        
        title = front_matter.get('title') or md_path.stem.replace('-', ' ').title()
        
        # N·∫øu body r·ªóng v√† c√≥ th√¥ng tin API trong front matter, parse t·ª´ OpenAPI JSON
        if not body and base_dir and front_matter.get('api'):
            api_file = front_matter['api'].get('file')
            operation_id = front_matter['api'].get('operationId')
            
            if api_file and operation_id:
                # T√¨m file OpenAPI JSON - th·ª≠ nhi·ªÅu v·ªã tr√≠
                possible_paths = [
                    base_dir / 'reference' / api_file,  # Root c·ªßa reference
                    md_path.parent / api_file,  # C√πng th∆∞ m·ª•c v·ªõi file .md
                    base_dir / api_file,  # Root c·ªßa export
                ]
                
                openapi_path = None
                for path in possible_paths:
                    if path.exists():
                        openapi_path = path
                        break
                
                if openapi_path:
                    try:
                        with open(openapi_path, 'r', encoding='utf-8-sig') as f:
                            openapi_spec = json.load(f)
                        html = parse_openapi_endpoint(openapi_spec, operation_id, title)
                        if html and html != "<p>API endpoint documentation not found in OpenAPI spec.</p>":
                            return {
                                'title': title,
                                'html_content': html,
                                'front_matter': front_matter,
                                'slug': md_path.stem
                            }
                        else:
                            print(f"    ‚ö†Ô∏è  Kh√¥ng t√¨m th·∫•y endpoint cho operationId '{operation_id}' ho·∫∑c title '{title}' trong {api_file}")
                    except json.JSONDecodeError as e:
                        print(f"    ‚ö†Ô∏è  L·ªói parse JSON t·ª´ {api_file}: {e}")
                    except Exception as e:
                        print(f"    ‚ö†Ô∏è  Kh√¥ng th·ªÉ parse OpenAPI t·ª´ {api_file}: {e}")
                else:
                    print(f"    ‚ö†Ô∏è  Kh√¥ng t√¨m th·∫•y file OpenAPI: {api_file} (ƒë√£ th·ª≠: {[str(p) for p in possible_paths]})")
        
        # Convert markdown to HTML (n·∫øu c√≥ body)
        if body:
            md = markdown.Markdown(extensions=['fenced_code', 'tables', 'nl2br'])
            html = md.convert(body)
        else:
            # N·∫øu kh√¥ng c√≥ body v√† kh√¥ng parse ƒë∆∞·ª£c t·ª´ OpenAPI, t·∫°o placeholder
            html = f"<p>N·ªôi dung cho <strong>{title}</strong></p>"
        
        return {
            'title': title,
            'html_content': html,
            'front_matter': front_matter,
            'slug': md_path.stem
        }
    except Exception as e:
        print(f"  ‚ö†Ô∏è  L·ªói parse {md_path}: {e}")
        return None


def find_md_files(directory: Path) -> List[Path]:
    """T√¨m t·∫•t c·∫£ file .md trong directory (recursive)"""
    md_files = []
    for root, dirs, files in os.walk(directory):
        for file in files:
            if file.endswith('.md') and file != '_order.yaml':
                md_files.append(Path(root) / file)
    return md_files


def build_doc_tree(base_dir: Path) -> List[Dict[str, Any]]:
    """X√¢y d·ª±ng c√¢y t√†i li·ªáu t·ª´ ReadMe export, t·∫°o parent ch·ªâ khi c√≥ d·ªØ li·ªáu"""
    all_docs = []
    file_counter = {'user_guide': 0, 'developer_guide': 0, 'release_notes': 0}
    
    def process_directory_recursive(current_dir: Path, parent_slug: str, section_key: str, base_path: Path, root_base_dir: Path):
        """ƒê·ªçc T·∫§T C·∫¢ file .md trong th∆∞ m·ª•c (recursive) v√† ƒë·∫∑t d∆∞·ªõi parent_slug, gi·ªØ th·ª© t·ª± t·ª´ _order.yaml"""
        # ƒê·ªçc _order.yaml ·ªü level hi·ªán t·∫°i
        order_path = current_dir / '_order.yaml'
        order_items = read_order_yaml(order_path)
        
        # T·∫°o danh s√°ch file ƒë√£ x·ª≠ l√Ω ƒë·ªÉ tr√°nh tr√πng
        processed = set()
        
        # X·ª≠ l√Ω theo th·ª© t·ª± trong _order.yaml
        for idx, item in enumerate(order_items):
            item_path = current_dir / item
            
            # N·∫øu l√† th∆∞ m·ª•c
            if item_path.is_dir():
                # ƒê·ªá quy x·ª≠ l√Ω th∆∞ m·ª•c con (gi·ªØ th·ª© t·ª± t·ª´ _order.yaml c·ªßa n√≥)
                process_directory_recursive(item_path, parent_slug, section_key, base_path, root_base_dir)
                
                # N·∫øu c√≥ index.md trong th∆∞ m·ª•c n√†y, c≈©ng x·ª≠ l√Ω
                index_md = item_path / 'index.md'
                if index_md.exists() and index_md not in processed:
                    doc_data = parse_markdown_file(index_md, root_base_dir)
                    if doc_data:
                        file_counter[section_key] += 1
                        doc_data['parent_slug'] = parent_slug
                        doc_data['order_index'] = file_counter[section_key]
                        doc_data['section'] = section_key
                        rel_path = index_md.relative_to(base_path)
                        doc_data['slug'] = str(rel_path).replace('\\', '/').replace('.md', '').replace('/', '-')
                        all_docs.append(doc_data)
                        processed.add(index_md)
            
            # N·∫øu l√† file .md tr·ª±c ti·∫øp
            elif (current_dir / f"{item}.md").exists():
                md_file = current_dir / f"{item}.md"
                if md_file not in processed:
                    doc_data = parse_markdown_file(md_file, root_base_dir)
                    if doc_data:
                        file_counter[section_key] += 1
                        doc_data['parent_slug'] = parent_slug
                        doc_data['order_index'] = file_counter[section_key]
                        doc_data['section'] = section_key
                        rel_path = md_file.relative_to(base_path)
                        doc_data['slug'] = str(rel_path).replace('\\', '/').replace('.md', '').replace('/', '-')
                        all_docs.append(doc_data)
                        processed.add(md_file)
        
        # X·ª≠ l√Ω c√°c file .md c√≤n l·∫°i trong th∆∞ m·ª•c hi·ªán t·∫°i (kh√¥ng c√≥ trong _order.yaml)
        for md_file in sorted(current_dir.glob('*.md')):
            if md_file.name != '_order.yaml' and md_file not in processed:
                doc_data = parse_markdown_file(md_file, root_base_dir)
                if doc_data:
                    file_counter[section_key] += 1
                    doc_data['parent_slug'] = parent_slug
                    doc_data['order_index'] = file_counter[section_key]
                    doc_data['section'] = section_key
                    rel_path = md_file.relative_to(base_path)
                    doc_data['slug'] = str(rel_path).replace('\\', '/').replace('.md', '').replace('/', '-')
                    all_docs.append(doc_data)
                    processed.add(md_file)
    
    # Process t·ª´ng th∆∞ m·ª•c TR∆Ø·ªöC ƒë·ªÉ ƒë·∫øm s·ªë documents
    # Process docs/ -> User Guide
    docs_dir = base_dir / 'docs'
    if docs_dir.exists() and docs_dir.is_dir():
        print(f"  üìÇ ƒêang ƒë·ªçc th∆∞ m·ª•c docs/...")
        process_directory_recursive(docs_dir, 'user-guide', 'user_guide', docs_dir, base_dir)
    
    # Process reference/ -> Developer Guide
    reference_dir = base_dir / 'reference'
    if reference_dir.exists() and reference_dir.is_dir():
        print(f"  üìÇ ƒêang ƒë·ªçc th∆∞ m·ª•c reference/...")
        process_directory_recursive(reference_dir, 'developer-guide', 'developer_guide', reference_dir, base_dir)
    
    # Process recipes/ -> Release Notes
    recipes_dir = base_dir / 'recipes'
    if recipes_dir.exists() and recipes_dir.is_dir():
        print(f"  üìÇ ƒêang ƒë·ªçc th∆∞ m·ª•c recipes/...")
        process_directory_recursive(recipes_dir, 'release-notes', 'release_notes', recipes_dir, base_dir)
    
    # CH·ªà t·∫°o parent khi c√≥ √≠t nh·∫•t 1 document trong section ƒë√≥
    parent_order = 1
    
    # 1. T·∫°o parent "User Guide" n·∫øu c√≥ documents
    if file_counter['user_guide'] > 0:
        user_guide_parent = {
            'title': 'User Guide',
            'html_content': '<p>T√†i li·ªáu h∆∞·ªõng d·∫´n s·ª≠ d·ª•ng cho ng∆∞·ªùi d√πng</p>',
            'section': 'user_guide',
            'order_index': parent_order,
            'parent_slug': None,
            'slug': 'user-guide',
            'is_parent': True
        }
        all_docs.insert(0, user_guide_parent)  # Insert ·ªü ƒë·∫ßu ƒë·ªÉ parent lu√¥n ƒë·ª©ng tr∆∞·ªõc children
        parent_order += 1
        print(f"  ‚úì T·∫°o parent 'User Guide' v·ªõi {file_counter['user_guide']} documents")
    else:
        print(f"  ‚ö†Ô∏è  B·ªè qua 'User Guide' v√¨ kh√¥ng c√≥ documents")
    
    # 2. T·∫°o parent "Developer Guide" n·∫øu c√≥ documents
    if file_counter['developer_guide'] > 0:
        dev_guide_parent = {
            'title': 'Developer Guide',
            'html_content': '<p>T√†i li·ªáu API v√† h∆∞·ªõng d·∫´n cho developer</p>',
            'section': 'developer_guide',
            'order_index': parent_order,
            'parent_slug': None,
            'slug': 'developer-guide',
            'is_parent': True
        }
        # T√¨m v·ªã tr√≠ insert: sau User Guide (n·∫øu c√≥) ho·∫∑c ƒë·∫ßu list
        insert_pos = 1 if file_counter['user_guide'] > 0 else 0
        all_docs.insert(insert_pos, dev_guide_parent)
        parent_order += 1
        print(f"  ‚úì T·∫°o parent 'Developer Guide' v·ªõi {file_counter['developer_guide']} documents")
    else:
        print(f"  ‚ö†Ô∏è  B·ªè qua 'Developer Guide' v√¨ kh√¥ng c√≥ documents")
    
    # 3. T·∫°o parent "Release Notes" n·∫øu c√≥ documents
    if file_counter['release_notes'] > 0:
        release_notes_parent = {
            'title': 'Release Notes',
            'html_content': '<p>Ghi ch√∫ phi√™n b·∫£n v√† c·∫≠p nh·∫≠t</p>',
            'section': 'release_notes',
            'order_index': parent_order,
            'parent_slug': None,
            'slug': 'release-notes',
            'is_parent': True
        }
        # T√¨m v·ªã tr√≠ insert: sau c√°c parent kh√°c
        insert_pos = sum(1 for k in ['user_guide', 'developer_guide'] if file_counter[k] > 0)
        all_docs.insert(insert_pos, release_notes_parent)
        print(f"  ‚úì T·∫°o parent 'Release Notes' v·ªõi {file_counter['release_notes']} documents")
    else:
        print(f"  ‚ö†Ô∏è  B·ªè qua 'Release Notes' v√¨ kh√¥ng c√≥ documents")
    
    return all_docs


def replace_image_urls(models, uid, html: str, base_zip_dir: Path) -> str:
    """Thay th·∫ø ·∫£nh:
    1) ∆Øu ti√™n ·∫£nh c·ª•c b·ªô trong ZIP (../assets/... ho·∫∑c ../files/...), upload l√™n Odoo v√† thay src.
    2) Link ngo√†i https:// gi·ªØ nguy√™n.
    3) Wrap ·∫£nh trong <figure> v·ªõi CSS ƒë·ªÉ ·∫£nh hi·ªÉn th·ªã g·ªçn: max-width:100%; height:auto; display:block; margin.
    """
    if not html:
        return ""

    pattern = r'<img\b[^>]*>'

    def add_attrs_to_img(tag_html: str) -> str:
        """Th√™m width, height, loading v√†o img tag n·∫øu ch∆∞a c√≥"""
        attrs = tag_html
        if ' width=' not in attrs:
            attrs = attrs.replace('<img', '<img width="100%"', 1)
        if ' height=' not in attrs:
            attrs = attrs.replace('<img', '<img height="auto"', 1)
        if ' loading=' not in attrs:
            attrs = attrs.replace('<img', '<img loading="lazy"', 1)
        return attrs

    def wrap_img(m):
        img_tag = m.group(0)
        # Wrap trong figure (kh√¥ng c·∫ßn check v√¨ ƒë√£ x·ª≠ l√Ω src tr∆∞·ªõc)
        img_tag = add_attrs_to_img(img_tag)
        return f'<figure style="max-width:100%;margin:12px 0">{img_tag}</figure>'

    # T√¨m v√† thay th·∫ø src cho ·∫£nh local tr∆∞·ªõc
    src_pattern = r'<img[^>]+src=["\']([^"\']+)["\']'
    
    def replacer_src(m):
        original_src = m.group(1)
        full_tag = m.group(0)

        # Cache
        if original_src in IMAGE_UPLOAD_CACHE:
            return full_tag.replace(original_src, IMAGE_UPLOAD_CACHE[original_src])

        # Local in ZIP
        if original_src.startswith(("../assets/", "../files/")):
            rel = original_src[3:]  # drop ../
            local_path = base_zip_dir / rel
            if local_path.exists():
                print(f"    ‚¨ÜÔ∏è  Upload ·∫£nh: {rel}")
                _, url = upload_attachment(models, uid, str(local_path), public=True)
                if url:
                    IMAGE_UPLOAD_CACHE[original_src] = url
                    return full_tag.replace(original_src, url)
            else:
                print(f"    ‚ö†Ô∏è  Kh√¥ng th·∫•y ·∫£nh: {local_path}")

        # External link: keep v√† cache
        if original_src.startswith(("http://", "https://")):
            IMAGE_UPLOAD_CACHE[original_src] = original_src

        return full_tag

    # Thay th·∫ø src tr∆∞·ªõc
    html = re.sub(src_pattern, replacer_src, html, flags=re.IGNORECASE)
    
    # Sau ƒë√≥ wrap t·∫•t c·∫£ img trong figure
    return re.sub(pattern, wrap_img, html, flags=re.IGNORECASE)


# ------------------- IMPORTER CH√çNH -------------------
def import_all():
    """Import t·∫•t c·∫£ docs t·ª´ ReadMe export v√†o Odoo"""
    models, uid = odoo_login()
    space_id = ensure_space(models, uid, SPACE_NAME)
    
    print("\nüìö ƒêang ƒë·ªçc c·∫•u tr√∫c t·ª´ ReadMe export...")
    base_dir = Path(README_EXPORT_DIR)
    if not base_dir.exists():
        raise SystemExit(f"‚ùå Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c export: {README_EXPORT_DIR}")
    
    all_docs = build_doc_tree(base_dir)
    print(f"  ‚úì T√¨m th·∫•y {len(all_docs)} t√†i li·ªáu")
    
    # S·∫Øp x·∫øp: parent articles tr∆∞·ªõc (theo order_index), sau ƒë√≥ l√† children (theo order_index)
    def sort_key(doc):
        is_parent = doc.get('is_parent', False)
        section = doc.get('section', 'unknown')
        order_idx = doc.get('order_index', 999999)
        # Parent articles c√≥ order_index 1, 2, 3 n√™n s·∫Ω ƒë∆∞·ª£c sort tr∆∞·ªõc
        # Children c√≥ order_index tƒÉng d·∫ßn trong t·ª´ng section
        section_order = {'user_guide': 1, 'developer_guide': 2, 'release_notes': 3}.get(section, 999)
        return (section_order, order_idx)
    
    all_docs.sort(key=sort_key)
    
    # G√°n sequence theo parent
    parent_to_next_seq: Dict[str, int] = {}
    for doc in all_docs:
        parent_key = doc.get('parent_slug') or '__root__'
        seq = parent_to_next_seq.get(parent_key, 1)
        doc['_id_seq'] = seq
        parent_to_next_seq[parent_key] = seq + 1
    
    print("\n" + "="*60)
    print("üöÄ B·∫ÆT ƒê·∫¶U QU√Å TR√åNH IMPORT...")
    print("="*60 + "\n")
    
    article_ids: Dict[str, int] = {}
    total_files = 0
    success_count = 0
    
    for doc in all_docs:
        total_files += 1
        try:
            title = doc.get('title', 'Untitled')
            slug = doc.get('slug', f'doc_{total_files}')
            html_content = doc.get('html_content', '')
            # Mirror ·∫£nh v√†o Odoo v√† th√™m CSS hi·ªÉn th·ªã g·ªçn
            html_content = replace_image_urls(models, uid, html_content, base_dir)
            id_seq = doc.get('_id_seq')
            
            print(f"\n[{total_files}] ƒêang x·ª≠ l√Ω: {title[:60]}")
            
            # T·∫°o ho·∫∑c c·∫≠p nh·∫≠t article
            vals = {
                "name": title,
                "body": html_content,
                "parent_id": space_id
            }
            if id_seq is not None:
                vals["sequence"] = id_seq
            
            # T√¨m article ƒë√£ t·ªìn t·∫°i
            existing_article = odoo_search(
                models, uid, MODEL_ARTICLE,
                [("name", "=", title), ("parent_id", "=", space_id)],
                ["id"], limit=1
            )
            
            if existing_article:
                rid = existing_article[0]["id"]
                odoo_write(models, uid, MODEL_ARTICLE, [rid], vals)
                article_ids[slug] = rid
                print(f"  ‚úì C·∫≠p nh·∫≠t b√†i vi·∫øt (ID: {rid})")
            else:
                aid = odoo_create(models, uid, MODEL_ARTICLE, vals)
                article_ids[slug] = aid
                print(f"  ‚úì T·∫°o m·ªõi b√†i vi·∫øt (ID: {aid})")
            
            success_count += 1
            
        except Exception as e:
            print(f"\n‚ùå L·ªñI khi x·ª≠ l√Ω '{slug}': {e}\n")
    
    # Set parent relationships
    print("\nüîó ƒêang thi·∫øt l·∫≠p quan h·ªá cha-con...")
    fixed = 0
    for doc in all_docs:
        try:
            parent_slug = doc.get('parent_slug')
            if not parent_slug:
                continue
            child_id = article_ids.get(doc.get('slug'))
            parent_id = article_ids.get(parent_slug)
            if child_id and parent_id:
                odoo_write(models, uid, MODEL_ARTICLE, [child_id], {"parent_id": parent_id})
                fixed += 1
        except Exception as e:
            print(f"  ‚ö†Ô∏è  Kh√¥ng th·ªÉ set parent cho '{doc.get('slug')}': {e}")
    
    if fixed:
        print(f"  ‚úì ƒê√£ set parent cho {fixed} b√†i vi·∫øt")
    
    print("\n" + "="*60)
    print(f"‚úÖ‚úÖ‚úÖ IMPORT HO√ÄN T·∫§T! ‚úÖ‚úÖ‚úÖ")
    print(f"   T·ªïng s·ªë file: {total_files}")
    print(f"   Th√†nh c√¥ng: {success_count}")
    print(f"   Th·∫•t b·∫°i: {total_files - success_count}")
    print(f"\nüìã H√£y ki·ªÉm tra k·∫øt qu·∫£ trong Odoo, kh√¥ng gian: '{SPACE_NAME}'")
    print("="*60)


# ------------------- UPLOAD RELEASE NOTES FROM JSON -------------------
def load_release_notes_from_json(base_dir: Path) -> List[Dict[str, Any]]:
    """Load c√°c Release Notes t·ª´ JSON files ƒë√£ scrape"""
    release_notes_dir = base_dir / 'release_notes' / 'content_release_notes'
    if not release_notes_dir.exists():
        print(f"  ‚ö†Ô∏è  Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c: {release_notes_dir}")
        return []
    
    all_docs = []
    json_files = sorted(release_notes_dir.glob('*.json'))
    
    print(f"\nüìÇ ƒêang ƒë·ªçc Release Notes t·ª´ JSON files...")
    print(f"  üìÅ Th∆∞ m·ª•c: {release_notes_dir}")
    print(f"  üìÑ T√¨m th·∫•y {len(json_files)} file JSON")
    
    for json_file in json_files:
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                doc_data = json.load(f)
            
            # B·ªè qua file changelog.json n·∫øu ch·ªâ l√† listing page (kh√¥ng c√≥ n·ªôi dung chi ti·∫øt)
            if json_file.name == 'changelog.json' and not doc_data.get('html_content', '').strip():
                print(f"  ‚è≠Ô∏è  B·ªè qua {json_file.name} (listing page)")
                continue
            
            # ƒê·∫£m b·∫£o c√≥ ƒë·∫ßy ƒë·ªß th√¥ng tin c·∫ßn thi·∫øt
            if not doc_data.get('title'):
                doc_data['title'] = json_file.stem.replace('_', ' ').title()
            
            if not doc_data.get('slug'):
                doc_data['slug'] = json_file.stem
            
            # Set section v√† parent_slug
            doc_data['section'] = 'release_notes'
            doc_data['parent_slug'] = 'release-notes'  # T·∫•t c·∫£ release notes ƒë·ªÅu d∆∞·ªõi parent n√†y
            
            all_docs.append(doc_data)
            
        except Exception as e:
            print(f"  ‚ö†Ô∏è  L·ªói ƒë·ªçc {json_file.name}: {e}")
    
    # S·∫Øp x·∫øp theo order_index (n·∫øu c√≥), sau ƒë√≥ theo title
    all_docs.sort(key=lambda x: (
        x.get('order_index', 999999),
        x.get('title', '').lower()
    ))
    
    print(f"  ‚úì ƒê√£ load {len(all_docs)} release notes")
    return all_docs


def replace_release_notes_images(models, uid, html: str, assets_dir: Path) -> str:
    """Thay th·∫ø ƒë∆∞·ªùng d·∫´n ·∫£nh trong release notes b·∫±ng URL Odoo"""
    if not assets_dir.exists():
        return html
    
    # Pattern ƒë·ªÉ t√¨m c√°c ·∫£nh t·ª´ files.readme.io ho·∫∑c local assets
    # T√¨m ·∫£nh t·ª´ files.readme.io (external) - gi·ªØ nguy√™n
    # T√¨m ·∫£nh local trong ../assets_release_notes/
    asset_pattern = r'src=["\']([^"\']*\.(?:png|jpg|jpeg|gif|svg|webp))["\']'
    
    def replace_img(match):
        original_url = match.group(1)
        img_tag = match.group(0)
        
        # N·∫øu l√† external URL (files.readme.io), gi·ªØ nguy√™n nh∆∞ng cache
        if original_url.startswith(('http://', 'https://')):
            if original_url not in IMAGE_UPLOAD_CACHE:
                IMAGE_UPLOAD_CACHE[original_url] = original_url
            return img_tag
        
        # N·∫øu l√† local asset (../assets_release_notes/...)
        if '../assets_release_notes/' in original_url or original_url.startswith('assets_release_notes/'):
            # L·∫•y t√™n file
            filename = os.path.basename(original_url)
            local_path = assets_dir / filename
            
            if filename in IMAGE_UPLOAD_CACHE:
                new_url = IMAGE_UPLOAD_CACHE[filename]
                return img_tag.replace(original_url, new_url)
            
            if local_path.exists():
                print(f"    ‚¨ÜÔ∏è  Upload ·∫£nh: {filename}")
                _, url = upload_attachment(models, uid, str(local_path), public=True)
                if url:
                    IMAGE_UPLOAD_CACHE[filename] = url
                    return img_tag.replace(original_url, url)
            else:
                print(f"    ‚ö†Ô∏è  Kh√¥ng t√¨m th·∫•y ·∫£nh: {local_path}")
        
        return img_tag
    
    html = re.sub(asset_pattern, replace_img, html, flags=re.IGNORECASE)
    return html


def import_release_notes():
    """Upload c√°c Release Notes ƒë√£ scrape t·ª´ JSON files l√™n Odoo"""
    models, uid = odoo_login()
    space_id = ensure_space(models, uid, SPACE_NAME)
    
    print("\n" + "="*60)
    print("üìã UPLOAD RELEASE NOTES T·ª™ JSON FILES")
    print("="*60)
    
    base_dir = Path(r"C:\Abivin\data_docs03")
    release_notes_dir = base_dir / 'release_notes' / 'content_release_notes'
    assets_dir = base_dir / 'release_notes' / 'assets_release_notes'
    
    if not release_notes_dir.exists():
        raise SystemExit(f"‚ùå Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c: {release_notes_dir}")
    
    # Load c√°c release notes t·ª´ JSON
    all_docs = load_release_notes_from_json(base_dir)
    
    if not all_docs:
        print("  ‚ö†Ô∏è  Kh√¥ng c√≥ release notes n√†o ƒë·ªÉ upload")
        return
    
    # T√¨m ho·∫∑c t·∫°o parent "Release Notes"
    print("\nüìÅ Ki·ªÉm tra parent 'Release Notes'...")
    release_notes_parent_id = None
    existing_parent = odoo_search(
        models, uid, MODEL_ARTICLE,
        [("name", "=", "Release Notes"), ("parent_id", "=", space_id)],
        ["id"], limit=1
    )
    
    if existing_parent:
        release_notes_parent_id = existing_parent[0]["id"]
        print(f"  ‚úì T√¨m th·∫•y parent 'Release Notes' (ID: {release_notes_parent_id})")
    else:
        # T·∫°o parent m·ªõi
        release_notes_parent_id = odoo_create(models, uid, MODEL_ARTICLE, {
            "name": "Release Notes",
            "body": "<p>Ghi ch√∫ phi√™n b·∫£n v√† c·∫≠p nh·∫≠t</p>",
            "parent_id": space_id,
            "sequence": 1000  # ƒê·∫∑t ·ªü cu·ªëi
        })
        print(f"  ‚úì T·∫°o m·ªõi parent 'Release Notes' (ID: {release_notes_parent_id})")
    
    print("\n" + "="*60)
    print("üöÄ B·∫ÆT ƒê·∫¶U UPLOAD RELEASE NOTES...")
    print("="*60 + "\n")
    
    article_ids: Dict[str, int] = {}
    total_files = 0
    success_count = 0
    
    # G√°n sequence cho m·ªói release note
    seq_counter = 1
    
    for doc in all_docs:
        total_files += 1
        try:
            title = doc.get('title', 'Untitled')
            slug = doc.get('slug', f'release_note_{total_files}')
            html_content = doc.get('html_content', '')
            
            # X·ª≠ l√Ω ·∫£nh
            if assets_dir.exists():
                html_content = replace_release_notes_images(models, uid, html_content, assets_dir)
            
            print(f"\n[{total_files}/{len(all_docs)}] ƒêang x·ª≠ l√Ω: {title[:60]}")
            
            # T·∫°o ho·∫∑c c·∫≠p nh·∫≠t article
            vals = {
                "name": title,
                "body": html_content,
                "parent_id": release_notes_parent_id,  # T·∫•t c·∫£ ƒë·ªÅu d∆∞·ªõi parent "Release Notes"
                "sequence": seq_counter
            }
            
            # T√¨m article ƒë√£ t·ªìn t·∫°i
            existing_article = odoo_search(
                models, uid, MODEL_ARTICLE,
                [("name", "=", title), ("parent_id", "=", release_notes_parent_id)],
                ["id"], limit=1
            )
            
            if existing_article:
                rid = existing_article[0]["id"]
                odoo_write(models, uid, MODEL_ARTICLE, [rid], vals)
                article_ids[slug] = rid
                print(f"  ‚úì C·∫≠p nh·∫≠t b√†i vi·∫øt (ID: {rid})")
            else:
                aid = odoo_create(models, uid, MODEL_ARTICLE, vals)
                article_ids[slug] = aid
                print(f"  ‚úì T·∫°o m·ªõi b√†i vi·∫øt (ID: {aid})")
            
            seq_counter += 1
            success_count += 1
            
        except Exception as e:
            print(f"\n‚ùå L·ªñI khi x·ª≠ l√Ω '{slug}': {e}\n")
            import traceback
            traceback.print_exc()
    
    print("\n" + "="*60)
    print(f"‚úÖ‚úÖ‚úÖ UPLOAD RELEASE NOTES HO√ÄN T·∫§T! ‚úÖ‚úÖ‚úÖ")
    print(f"   T·ªïng s·ªë file: {total_files}")
    print(f"   Th√†nh c√¥ng: {success_count}")
    print(f"   Th·∫•t b·∫°i: {total_files - success_count}")
    print(f"\nüìã H√£y ki·ªÉm tra k·∫øt qu·∫£ trong Odoo, section: 'Release Notes'")
    print("="*60)


# -------------------- MAIN ---------------------------
if __name__ == "__main__":
    try:
        # Ch·ªçn function c·∫ßn ch·∫°y:
        # - import_all() : Import t·ª´ ReadMe ZIP export
        # - import_release_notes() : Upload Release Notes t·ª´ JSON files ƒë√£ scrape
        
        import_release_notes()  # Upload Release Notes t·ª´ JSON
        # import_all()  # Ho·∫∑c import t·ª´ ZIP export
        
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  Ng∆∞·ªùi d√πng h·ªßy b·ªè qu√° tr√¨nh import!")
    except Exception as e:
        print(f"\n‚ùå L·ªñI NGHI√äM TR·ªåNG: {e}")
        import traceback
        traceback.print_exc()

