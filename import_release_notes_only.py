# =============================================================
# File: import_release_notes_only.py  (Odoo 18/19 compatible)
# Purpose: Diagnose & import ONLY "Release Notes / Changelog" from a
#           ReadMe ZIP export into Odoo Knowledge.
# Author: Generated by ChatGPT assistant (diagnostic-focused)
# =============================================================

import os
import re
import sys
import csv
import json
import yaml
import base64
import argparse
import xmlrpc.client
from pathlib import Path
from typing import Dict, List, Tuple, Any, Optional

# ---------- Console UTF-8 on Windows ----------
if sys.platform == 'win32':
    try:
        sys.stdout.reconfigure(encoding='utf-8')
    except Exception:
        pass

# ---------- User Defaults (can be overridden by CLI) ----------
README_EXPORT_DIR = r"C:\Abivin\data_docs03\abivin-v4.0-2025-11-03T16-58-05_8cddcbc"
ODOO_BASE_URL     = "https://test018.odoo.com"
ODOO_DB_NAME      = "test018"
ODOO_USER         = "trinhcongduc0112@gmail.com"
ODOO_API_KEY      = "3f623d85508792f81af911610db742d67a5d1845"   # <-- Ä‘iá»n API key (hoáº·c truyá»n qua --apikey)
SPACE_NAME        = "TÃ i liá»‡u Abivin 05"

MODEL_ARTICLE     = "knowledge.article"
MODEL_ATTACHMENT  = "ir.attachment"

# ---------- Globals ----------
IMAGE_UPLOAD_CACHE: Dict[str, str] = {}
SPACE_FIELD: Optional[str] = None
SPACE_MODEL_NAME: Optional[str] = None

LIKELY_RELEASE_DIR_NAMES = [
    "release", "releases", "release-notes", "release_notes",
    "changelog", "change-log", "changes", "what-is-new", "whats-new",
    "updates", "versions", "version-history", "news", "recipes"
]

MD_EXTENSIONS = (".md",)


# ---------- XML-RPC Core ----------
def odoo_login(base_url: str, db: str, user: str, api_key: str) -> Tuple[xmlrpc.client.ServerProxy, int]:
    print("ðŸ” Káº¿t ná»‘i Odoo...")
    common = xmlrpc.client.ServerProxy(f"{base_url}/xmlrpc/2/common")
    try:
        ver = common.version()
        print(f"   âœ“ Server: {ver.get('server_version', 'Unknown')}")
    except Exception as e:
        print(f"   âš ï¸  KhÃ´ng Ä‘á»c Ä‘Æ°á»£c phiÃªn báº£n: {e}")
    uid = common.authenticate(db, user, api_key, {})
    if not uid:
        raise SystemExit("âŒ XÃ¡c thá»±c tháº¥t báº¡i (API key/quyá»n).")
    print(f"   âœ“ UID: {uid}")
    return xmlrpc.client.ServerProxy(f"{base_url}/xmlrpc/2/object"), uid


def odoo_call(models, uid, db, api_key, model, method, *args, **kwargs):
    args = list(args) if args else []
    kwargs = kwargs or {}
    for attempt in range(3):
        try:
            return models.execute_kw(db, uid, api_key, model, method, args, kwargs)
        except Exception as e:
            print(f"   [RPC ERROR] {model}.{method} attempt {attempt+1}/3: {e}")
            import time; time.sleep(1.6)
    raise RuntimeError(f"âŒ RPC {model}.{method} failed x3.")


def odoo_search(models, uid, db, api_key, model, domain, fields=None, limit=0):
    kwargs = {}
    if fields: kwargs["fields"] = fields
    if limit: kwargs["limit"] = limit
    return odoo_call(models, uid, db, api_key, model, "search_read", domain, **kwargs)


def odoo_create(models, uid, db, api_key, model, vals):
    return odoo_call(models, uid, db, api_key, model, "create", [vals])


def odoo_write(models, uid, db, api_key, model, ids, vals):
    if not isinstance(ids, list): ids = [ids]
    return odoo_call(models, uid, db, api_key, model, "write", [ids, vals])


# ---------- Attachments (Images) ----------
def guess_mimetype(name: str) -> str:
    ext = os.path.splitext(name.lower())[1]
    return {
        ".png": "image/png", ".jpg": "image/jpeg", ".jpeg": "image/jpeg",
        ".gif": "image/gif", ".svg": "image/svg+xml", ".webp": "image/webp",
        ".avif": "image/avif", ".bmp": "image/bmp", ".ico": "image/x-icon",
        ".mp4": "video/mp4", ".mov": "video/quicktime"
    }.get(ext, "application/octet-stream")


def upload_attachment(models, uid, db, api_key, path: str, public=True) -> Tuple[Optional[int], Optional[str]]:
    try:
        with open(path, "rb") as f:
            datas_b64 = base64.b64encode(f.read()).decode()
        att_id = odoo_create(models, uid, db, api_key, MODEL_ATTACHMENT, {
            "name": os.path.basename(path),
            "datas": datas_b64,
            "mimetype": guess_mimetype(path),
            "public": public
        })
        att = odoo_search(models, uid, db, api_key, MODEL_ATTACHMENT, [("id","=",att_id)], ["checksum","name"], limit=1)
        qs = f"?unique={att[0]['checksum']}" if att and att[0].get("checksum") else ""
        url = f"/web/image/{att_id}/{att[0].get('name')}{qs}"
        return att_id, url
    except Exception as e:
        print(f"   âœ— Lá»—i upload '{path}': {e}")
        return None, None


# ---------- Space Detection ----------
def detect_space_field(models, uid, db, api_key):
    global SPACE_FIELD, SPACE_MODEL_NAME
    if SPACE_FIELD is not None:
        return SPACE_FIELD, SPACE_MODEL_NAME
    fields = odoo_call(models, uid, db, api_key, MODEL_ARTICLE, "fields_get", [], {"attributes": ["string", "type", "relation"]})
    for f in ("space_id", "collection_id", "workspace_id"):
        if f in fields and fields[f].get("type") == "many2one":
            SPACE_FIELD, SPACE_MODEL_NAME = f, fields[f].get("relation")
            print(f"   âœ“ Space field: {SPACE_FIELD} ({SPACE_MODEL_NAME})")
            return SPACE_FIELD, SPACE_MODEL_NAME
    SPACE_FIELD, SPACE_MODEL_NAME = None, None
    print("   â€¢ KhÃ´ng cÃ³ field Space. Sáº½ dÃ¹ng bÃ i gá»‘c lÃ m 'Space giáº£'.")
    return None, None


def ensure_space(models, uid, db, api_key, space_name: str) -> int:
    f, rel = detect_space_field(models, uid, db, api_key)
    if f and rel:
        rec = odoo_search(models, uid, db, api_key, rel, [("name","=",space_name)], ["id"], limit=1)
        if rec:
            print(f"   âœ“ DÃ¹ng {rel} '{space_name}' (ID {rec[0]['id']})")
            return rec[0]["id"]
        sid = odoo_create(models, uid, db, api_key, rel, {"name": space_name})
        print(f"   âœ“ Táº¡o {rel} '{space_name}' (ID {sid})")
        return sid
    # Fallback root article
    rec = odoo_search(models, uid, db, api_key, MODEL_ARTICLE, [("name","=",space_name), ("parent_id","=",False)], ["id"], limit=1)
    if rec:
        print(f"   âœ“ DÃ¹ng bÃ i gá»‘c '{space_name}' (ID {rec[0]['id']})")
        return rec[0]["id"]
    aid = odoo_create(models, uid, db, api_key, MODEL_ARTICLE, {
        "name": space_name,
        "body": "<p>Root for ReadMe Release Notes import</p>",
        "parent_id": False,
    })
    print(f"   âœ“ Táº¡o bÃ i gá»‘c '{space_name}' (ID {aid})")
    return aid


# ---------- Markdown Parsing ----------
def split_front_matter(text: str) -> Tuple[Dict[str, Any], str]:
    if text.startswith('---'):
        parts = text.split('---', 2)
        if len(parts) >= 3:
            try:
                fm = yaml.safe_load(parts[1]) or {}
                return fm, parts[2].strip()
            except Exception:
                return {}, text
    return {}, text


def md_to_html(md_text: str) -> str:
    try:
        import markdown
        md = markdown.Markdown(extensions=['fenced_code','tables','nl2br'])
        return md.convert(md_text)
    except Exception:
        return "<pre>" + (
            md_text.replace("&","&amp;").replace("<","&lt;").replace(">","&gt;")
        ) + "</pre>"


# ---------- Discovery of Release Notes ----------
def is_likely_release_path(p: Path) -> bool:
    low = str(p).lower()
    return any(seg in low for seg in LIKELY_RELEASE_DIR_NAMES)



def read_order_list(order_path: Path):
    """Read a simple YAML list from _order.yaml; return list of md basenames (without .md)."""
    if not order_path.exists():
        return []
    try:
        data = yaml.safe_load(order_path.read_text(encoding="utf-8")) or []
        items = []
        for x in data if isinstance(data, list) else []:
            s = str(x).strip()
            if s.endswith(".md"):
                s = s[:-3]
            items.append(s)
        return items
    except Exception as e:
        print(f"   âš ï¸  Lá»—i Ä‘á»c order file {order_path}: {e}")
        return []



def discover_release_md(base_dir: Path) -> List[Path]:
    candidates: List[Path] = []

    # 0) If recipes/_order.yaml exists, use that order explicitly
    recipes_dir = base_dir / "recipes"
    order_file = recipes_dir / "_order.yaml"
    if recipes_dir.exists() and order_file.exists():
        order_items = read_order_list(order_file)
        if order_items:
            for item in order_items:
                md = recipes_dir / f"{item}.md"
                if md.exists():
                    candidates.append(md)
            # Also include any other *.md files in recipes not listed, appended after
            listed = { (recipes_dir / f"{i}.md").resolve() for i in order_items }
            for extra in sorted(recipes_dir.glob("*.md")):
                if extra.resolve() not in listed:
                    candidates.append(extra)
            # Dedup and return early; we trust _order.yaml as authoritative
            seen = set(); uniq = []
            for pth in candidates:
                rp = pth.resolve()
                if rp not in seen:
                    seen.add(rp); uniq.append(pth)
            return uniq

    # 1) Prefer dirs
    for root, dirs, files in os.walk(base_dir):
        root_path = Path(root)
        if is_likely_release_path(root_path):
            for fn in files:
                if fn.lower().endswith(MD_EXTENSIONS):
                    candidates.append(root_path / fn)

    # 2) Fallback: filenames across repo
    if not candidates:
        for p in base_dir.rglob("*.md"):
            lname = p.name.lower()
            if any(k in lname for k in ("release", "changelog", "what's-new", "whats-new", "update", "version")):
                candidates.append(p)

    # 3) Deduplicate while keeping order
    seen = set()
    uniq: List[Path] = []
    for p in candidates:
        rp = p.resolve()
        if rp not in seen:
            seen.add(rp)
            uniq.append(p)
    return uniq


# ---------- Image URL Rewriter ----------
IMG_TAG_RE = re.compile(r'<img\b[^>]*>', re.IGNORECASE)
SRC_RE = re.compile(r'<img[^>]+src=["\']([^"\']+)["\']', re.IGNORECASE)
SRCSET_RE = re.compile(r'(srcset)=["\']([^"\']+)["\']', re.IGNORECASE)
SOURCE_SRCSET_RE = re.compile(r'(<source[^>]+srcset=["\'])([^"\']+)(["\'])', re.IGNORECASE)
URL_IN_STYLE_RE = re.compile(r'url\((["\']?)([^)\'"]+)\1\)', re.IGNORECASE)

def replace_image_urls(models, uid, db, api_key, html: str, base_zip_dir: Path) -> str:
    if not html: return ""

    def add_attrs(tag_html: str) -> str:
        style_attrs = 'style="max-width:800px!important;height:auto!important;display:block!important;object-fit:contain!important;"'
        if ' style=' not in tag_html:
            tag_html = tag_html.replace('<img', f'<img {style_attrs}', 1)
        else:
            tag_html = re.sub(r'style="[^"]*"', style_attrs, tag_html)
        if ' loading=' not in tag_html:
            tag_html = tag_html.replace('<img', '<img loading="lazy"', 1)
        return tag_html

    def wrap_img(m):
        return f'<figure style="max-width:800px;margin:12px auto;display:block;text-align:center;">{add_attrs(m.group(0))}</figure>'

    def _upload_local(local_rel: str) -> Optional[str]:
        local_rel_norm = re.sub(r'^(\.\./|\./|/)', '', local_rel)
        local_path = (base_zip_dir / local_rel_norm).resolve()
        if local_path.exists():
            key = str(local_path)
            if key in IMAGE_UPLOAD_CACHE:
                return IMAGE_UPLOAD_CACHE[key]
            print(f"     â¬†ï¸  Upload áº£nh: {local_rel_norm}")
            _, new_url = upload_attachment(models, uid, db, api_key, str(local_path), public=True)
            if new_url:
                IMAGE_UPLOAD_CACHE[key] = new_url
                return new_url
        else:
            print(f"     âš ï¸  KhÃ´ng tháº¥y áº£nh: {local_path}")
        return None

    def replacer_src(m):
        original_src, full_tag = m.group(1), m.group(0)
        if original_src in IMAGE_UPLOAD_CACHE:
            return full_tag.replace(original_src, IMAGE_UPLOAD_CACHE[original_src])

        if re.match(r'(\.\./|\./|/)?(assets|files)[/\\]', original_src, re.IGNORECASE):
            new_url = _upload_local(original_src)
            if new_url:
                IMAGE_UPLOAD_CACHE[original_src] = new_url
                return full_tag.replace(original_src, new_url)

        if original_src.startswith(("http://","https://")):
            IMAGE_UPLOAD_CACHE[original_src] = original_src
        return full_tag

    def replacer_srcset_match(attr, srcset_val):
        parts = [p.strip() for p in srcset_val.split(',')]
        new_parts = []
        for p in parts:
            if not p: continue
            url_part = p.split()[0]
            rest = p[len(url_part):]
            mapped = IMAGE_UPLOAD_CACHE.get(url_part)
            if not mapped and re.match(r'(\.\./|\./|/)?(assets|files)[/\\]', url_part, re.IGNORECASE):
                mapped = _upload_local(url_part)
                if mapped: IMAGE_UPLOAD_CACHE[url_part] = mapped
            new_parts.append(f"{(mapped or url_part)}{rest}")
        return f'{attr}="' + ", ".join(new_parts) + '"'

    html = re.sub(SRC_RE, replacer_src, html)
    html = re.sub(IMG_TAG_RE, wrap_img, html)
    html = SRCSET_RE.sub(lambda m: replacer_srcset_match(m.group(1), m.group(2)), html)
    html = SOURCE_SRCSET_RE.sub(lambda m: m.group(1) + replacer_srcset_match('srcset', m.group(2)).split('=',1)[1].strip('"\'') + m.group(3), html)

    def css_url_replacer(m):
        quote, u = m.group(1), m.group(2)
        new_u = IMAGE_UPLOAD_CACHE.get(u)
        if not new_u and re.match(r'(\.\./|\./|/)?(assets|files)[/\\]', u, re.IGNORECASE):
            new_u = _upload_local(u)
            if new_u: IMAGE_UPLOAD_CACHE[u] = new_u
        return f"url({quote}{(new_u or u)}{quote})"
    html = URL_IN_STYLE_RE.sub(css_url_replacer, html)

    return html


# ---------- Core: Build Release Docs ----------
def split_front_matter(text: str) -> Tuple[Dict[str, Any], str]:
    if text.startswith('---'):
        parts = text.split('---', 2)
        if len(parts) >= 3:
            try:
                fm = yaml.safe_load(parts[1]) or {}
                return fm, parts[2].strip()
            except Exception:
                return {}, text
    return {}, text


def parse_md_file(md_path: Path) -> Dict[str, Any]:
    try:
        text = md_path.read_text(encoding="utf-8")
    except UnicodeDecodeError:
        text = md_path.read_text(encoding="utf-8-sig")
    except Exception as e:
        return {"path": str(md_path), "error": f"read_error:{e}"}
    fm, body = split_front_matter(text)
    title = fm.get("title") or md_path.stem.replace('-', ' ').title()
    if not body.strip():
        # Fallback: if body empty but there is 'description' in FM, use it
        desc = fm.get("description", "")
        body = desc if isinstance(desc, str) else ""
    return {"path": str(md_path), "title": title, "front_matter": fm, "body": body}


def build_release_docs(zip_root: Path) -> Tuple[List[Dict[str, Any]], List[Dict[str, Any]]]:
    diag: List[Dict[str, Any]] = []
    candidates = discover_release_md(zip_root)

    docs: List[Dict[str, Any]] = []
    order_idx = 0
    for p in candidates:
        rec = parse_md_file(p)
        if "error" in rec:
            diag.append({"path": rec["path"], "status": "skipped", "reason": rec["error"]})
            continue
        title, body = rec["title"], rec["body"]
        fm = rec.get("front_matter", {}) or {}

        # Heuristics: accept any Markdown under 'recipes' OR files that look like release notes
        signals = 0
        low = (title + " " + body[:250]).lower()
        for kw in ("release", "changelog", "what's new", "whats new", "updated", "fix", "improvement", "version"):
            if kw in low: signals += 1
        path_is_releasey = is_likely_release_path(Path(rec["path"]))
        under_recipes = str(rec["path"]).lower().find("recipes") != -1
        if not (under_recipes or path_is_releasey or signals):
            diag.append({"path": rec["path"], "status": "skipped", "reason": "not_release_like"})
            continue

        if not body.strip():
            diag.append({"path": rec["path"], "status": "skipped", "reason": "empty_content_after_fallback"})
            continue

        # Build slug
        rel = p.relative_to(zip_root)
        slug = str(rel).replace('\\','/').replace('.md','').replace('/','-')

        docs.append({
            "title": title,
            "body_md": body,
            "front_matter": fm,
            "slug": slug,
            "source_path": str(rel),
            "order_index": (order_idx := order_idx + 1),
        })
        diag.append({"path": rec["path"], "status": "accepted", "slug": slug, "order_index": order_idx})
    return docs, diag


# ---------- Importer ----------
def import_release_notes(
    base_dir: Path,
    odoo_url: str,
    odoo_db: str,
    odoo_user: str,
    odoo_key: str,
    space_name: str,
    parent_title: str = "Release Notes",
    dry_run: bool = False, # <-- THAY Äá»”I 1: Äá»•i máº·c Ä‘á»‹nh thÃ nh False
    report_json: Optional[Path] = None,
    report_csv: Optional[Path] = None,
):
    models, uid = odoo_login(odoo_url, odoo_db, odoo_user, odoo_key)
    space_id = ensure_space(models, uid, odoo_db, odoo_key, space_name)

    print("\nðŸ”Ž QuÃ©t cÃ¡c file cÃ³ kháº£ nÄƒng lÃ  Release Notes...")
    docs, diag = build_release_docs(base_dir)
    print(f"   â€¢ á»¨ng viÃªn tÃ¬m tháº¥y: {len(docs)} (xem thÃªm trong report)")

    # Prepare reports
    report = {
        "base_dir": str(base_dir),
        "total_candidates": len(docs),
        "diagnostics": diag,
    }
    if report_json:
        report_json.parent.mkdir(parents=True, exist_ok=True)
        report_json.write_text(json.dumps(report, ensure_ascii=False, indent=2), encoding="utf-8")
        print(f"   âœ“ Ghi report JSON: {report_json}")
    if report_csv:
        report_csv.parent.mkdir(parents=True, exist_ok=True)
        with report_csv.open("w", newline="", encoding="utf-8") as f:
            w = csv.writer(f)
            w.writerow(["path","status","reason_or_slug","order_index"])
            for d in diag:
                w.writerow([d.get("path"), d.get("status"), d.get("reason") or d.get("slug",""), d.get("order_index","")])
        print(f"   âœ“ Ghi report CSV:   {report_csv}")

    # Build parent article (top level) if needed
    print("\nðŸ“‘ Chuáº©n bá»‹ bÃ i cha 'Release Notes'...")
    domain_parent = [("name","=",parent_title), ("parent_id","=",False)]
    if SPACE_FIELD:
        domain_parent.append((SPACE_FIELD,"=",space_id))
    existing_parent = odoo_search(models, uid, odoo_db, odoo_key, MODEL_ARTICLE, domain_parent, ["id"], limit=1)

    if dry_run:
        parent_id = existing_parent[0]["id"] if existing_parent else None
        print(f"   [DRY] parent_id = {parent_id or '(chÆ°a cÃ³)'}")
    else:
        if existing_parent:
            parent_id = existing_parent[0]["id"]
            print(f"   âœ“ DÃ¹ng bÃ i cha sáºµn cÃ³ (ID {parent_id})")
        else:
            vals = {"name": parent_title, "body": "<p>Ghi chÃº phiÃªn báº£n</p>", "parent_id": False}
            if SPACE_FIELD:
                vals[SPACE_FIELD] = space_id
            parent_id = odoo_create(models, uid, odoo_db, odoo_key, MODEL_ARTICLE, vals)
            print(f"   âœ“ Táº¡o bÃ i cha (ID {parent_id})")

    # Import children
    print("\nðŸšš Import cÃ¡c release notes...")
    count_ok = 0
    for d in docs:
        title = d["title"]
        slug  = d["slug"]
        body_md = d["body_md"]
        html_body = md_to_html(body_md)
        html_body = replace_image_urls(models, uid, odoo_db, odoo_key, html_body, base_dir)

        # Domain tÃ¬m bÃ i cÅ© theo title + parent
        domain = [("name","=",title)]
        # In dry-run, parent_id is unknown => still try to detect existing under any parent (non-root) to warn on duplicates
        if SPACE_FIELD:
            domain.append((SPACE_FIELD,"=",space_id))

        if dry_run:
            print(f"   [DRY] Would upsert: '{title}' (order={d['order_index']})")
            count_ok += 1
            continue

        # when not dry-run, ensure we have/create parent_id above then enforce it here
        domain_parent = [("name","=",parent_title), ("parent_id","=",False)]
        if SPACE_FIELD:
            domain_parent.append((SPACE_FIELD,"=",space_id))
        parent_rec = odoo_search(models, uid, odoo_db, odoo_key, MODEL_ARTICLE, domain_parent, ["id"], limit=1)
        parent_id = parent_rec[0]["id"] if parent_rec else False

        if parent_id:
            domain.append(("parent_id","=",parent_id))

        existing = odoo_search(models, uid, odoo_db, odoo_key, MODEL_ARTICLE, domain, ["id"], limit=1)
        vals = {"name": title, "body": html_body, "sequence": d["order_index"]}
        if parent_id: vals["parent_id"] = parent_id
        if SPACE_FIELD: vals[SPACE_FIELD] = space_id
        if existing:
            rid = existing[0]["id"]
            odoo_write(models, uid, odoo_db, odoo_key, MODEL_ARTICLE, [rid], vals)
            print(f"   âœ“ Cáº­p nháº­t: {title} (ID {rid})")
        else:
            aid = odoo_create(models, uid, odoo_db, odoo_key, MODEL_ARTICLE, vals)
            print(f"   âœ“ Táº¡o má»›i: {title} (ID {aid})")
        count_ok += 1

    print("\n================== SUMMARY ==================")
    print(f"Base dir        : {base_dir}")
    print(f"Candidates      : {len(docs)}")
    print(f"Imported (ok)   : {count_ok}{' (dry-run)' if dry_run else ''}")
    print(f"Space           : '{space_name}'  ({'Space field' if SPACE_FIELD else 'Root article fallback'})")
    print("=============================================")


def main():
    ap = argparse.ArgumentParser(description="Release Notes importer/diagnostic for ReadMe ZIP -> Odoo Knowledge")
    ap.add_argument("--src", help=f"Path to ReadMe export (unzipped). Default: {README_EXPORT_DIR!r}")
    ap.add_argument("--url", help=f"Odoo base URL. Default: {ODOO_BASE_URL!r}")
    ap.add_argument("--db", help=f"Odoo DB name. Default: {ODOO_DB_NAME!r}")
    ap.add_argument("--user", help=f"Odoo user (email). Default: {ODOO_USER!r}")
    ap.add_argument("--apikey", help="Odoo API key. Default: value in script (may be empty).")
    ap.add_argument("--space", help=f"Space/Collection name. Default: {SPACE_NAME!r}")
    ap.add_argument("--parent", default="Release Notes", help="Parent article title (default: Release Notes)")
    # <-- THAY Äá»”I 2: Äá»•i tÃªn cá» thÃ nh --dry-run
    ap.add_argument("--dry-run", action="store_true", help="Run in simulation mode (default is real run)")
    ap.add_argument("--report-json", help="Write diagnostics JSON to this path")
    ap.add_argument("--report-csv", help="Write diagnostics CSV to this path")
    args = ap.parse_args()

    # Apply defaults if CLI not provided
    base_dir  = Path((args.src or README_EXPORT_DIR)).resolve()
    odoo_url  = (args.url or ODOO_BASE_URL).rstrip("/")
    odoo_db   = (args.db or ODOO_DB_NAME)
    odoo_user = (args.user or ODOO_USER)
    odoo_key  = (args.apikey if args.apikey is not None else ODOO_API_KEY)
    space     = (args.space or SPACE_NAME)

    if not base_dir.exists():
        raise SystemExit(f"âŒ KhÃ´ng tháº¥y thÆ° má»¥c: {base_dir}")
    if not odoo_key:
        print("âš ï¸  ChÆ°a cÃ³ API key. Truyá»n qua --apikey hoáº·c Ä‘iá»n ODOO_API_KEY trong script.", file=sys.stderr)

    # <-- THAY Äá»”I 3: Cáº­p nháº­t logic Ä‘á»ƒ Ä‘á»c cá» má»›i
    dry = args.dry_run
    report_json = Path(args.report_json).resolve() if args.report_json else None
    report_csv  = Path(args.report_csv).resolve() if args.report_csv else None
    import_release_notes(
        base_dir=base_dir,
        odoo_url=odoo_url,
        odoo_db=odoo_db,
        odoo_user=odoo_user,
        odoo_key=odoo_key,
        space_name=space,
        parent_title=args.parent,
        dry_run=dry,
        report_json=report_json,
        report_csv=report_csv,
    )


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\nâš ï¸ Há»§y bá»Ÿi ngÆ°á»i dÃ¹ng")
    except Exception as e:
        print(f"\nâŒ Lá»–I: {e}")
        import traceback; traceback.print_exc()